\chapter{Evaluation}\label{chap:evaluation}

This section reflects the results of all the testing performed with the different programming languages and architectures / types of computer.

\begin{table}[ht]
  \centering
  \begin{tabular}{lcccc}
    \toprule
                            & C\++                  & Go        & Python        & PyPy \\
    \midrule
    Intel Xeon Gold 6326 x2 &  GCC 14.2.0           & go1.24.2  & Python 3.12.3 & PyPy 7.3.19 \\
    MacbookPro M4 Pro       &  Apple Clang 17.0.0   & go1.24.2  & Python 3.13.3 & PyPy 7.3.19 \\
    Raspberry Pi 5          &                       &           &               &             \\
    Ryzen 3800x Desktop     &                       &           &               &             \\
    \bottomrule
  \end{tabular}
  \caption{Comparison of language performance on different platforms}
  \label{tab:lang-platforms}
\end{table}

It should be noted that Python should not be used for performance-critical applications, as it is an interpreted language and is not designed for high-performance computing. However, it is an excellent language for rapid prototyping and development, and it is widely used in the industry.

Go's intent is to be a fast, efficient, and easy-to-use language. It is designed for multithreading and concurrency, which makes it a great choice for high-performance computing. Go was specifically designed for backend development for web applications and is widely used in the industry.

\section{Measurement Platforms}

\subsection{Many-Core Platform}

This platform represents the most powerful as well as power-hungry combination of all devices in my test suite. This is a rack server with two Intel Xeon Gold 6326 processors, each having 16 cores and 32 threads, contributing to a total of 32 cores and 64 threads. It also has the largest amount of \gls{ram} from this testing, with 256GB of \gls{DDR4} memory.

As it has two sockets (one per CPU chip), there must be intercommunication between these processors if a process spreads out to more than 32 threads, or is set by the user using the command \texttt{taskset}, which fixes the cores the process can run on.



%% Comments on the platform, ie two xeon 16 cores processors with hyperthreading, x86
\subsubsection{Evaluated Parameters}

This system was the most versatile in terms of the number of tests that could be performed, as it has many processors and uses Linux on x86, providing a great advantage for forcing processes to run on specific cores.

The tests were conducted on a variety of core configurations, always setting cores in the same processor for core numbers less than 16.

\begin{itemize}
    \item \textbf{1 Core}: Testing with one core, producing the baseline for the program's energy consumption and execution time.
    \item \textbf{2 Cores}: Testing with 2 cores provides the first glimpse of parallelization benefits.
    \item \textbf{4 Cores}: Testing with 4 cores because many computers from some time ago had four cores.
    \item \textbf{8 Cores}: Testing with 8 cores gives us great insight into how many processors in the market work, and it is half the amount of cores inside one chip.
    \item \textbf{14 Cores}: Testing with 14 cores, because it is the number of cores available on the laptop and we wanted to have an execution time comparison.
    \item \textbf{16 Cores}: Testing with 16 cores as it is the amount of real cores on a single chip. This should be one of the most energy-efficient and fastest tests, if there were only one \gls{cpu}.
    \item \textbf{28 Cores (different \glspl{cpu}, all real cores, no logical cores)}: Testing with 28 cores distributed across two sockets is interesting because there has to be information sharing over the bus inside the motherboard to synchronize both \glspl{cpu}. This won't be as energy efficient, but may be faster.
    \item \textbf{28 Cores (same CPU, 16 cores, 32 virtual cores)}: Testing with 28 cores inside the same CPU; the performance should be slower as there are fewer real cores to tackle the work, but it has the advantage of not needing to share data with another socket.
    \item \textbf{32 Cores (same socket)}: Testing with 32 cores in the same socket uses all available logical threads of a system: the 16 real cores and the other 16 threads the \gls{cpu} has thanks to Hyper-Threading.
    \item \textbf{32 Cores (only real cores)}: Testing with 32 real cores across two sockets should be the most powerful combination for CPU-intensive tasks, as all operations should be able to be carried out without many interruptions.
    \item \textbf{48 Cores}: Testing with 48 cores forces us to use all real cores and some logical cores.
    \item \textbf{60 Cores}: Testing with 60 cores is also interesting (not 64), as this would force the machine to interrupt the program we are benchmarking to perform routine operations, such as checking for incoming connections or logging.
\end{itemize}

\subsubsection{Results}

The results for the server are shown in the following figures and tables. The energy consumption is measured in joules, and the execution time is measured in seconds. 

\input{parts/results/server-energy-pkg}

\input{parts/results/server-energy-ram}

\input{parts/results/server-execution-time}


From \autoref{fig:server-energy-pkg}, we can see that the energy consumption of the server is not linear with the number of cores. It can be observed that the energy consumption decreases as the number of cores increases, but there is a point in the graph and \autoref{tab:server-energy-pkg} where the energy consumption starts to increase slightly again, as well as the execution times in \autoref{fig:server-execution-time}, but not as much as the energy consumption.

This is due to hyperthreading\footnote{Hyperthreading is enabled in this system as it is not mine and I cannot disable it to perform testing. To set the process to a fixed \gls{cpu}, I used \texttt{taskset -c [cores]}, i.e., \texttt{taskset -c 0-15,32-47} for running across multiple \glspl{cpu} and \texttt{taskset -c 0-31} to force the program to only run in a single \gls{cpu}.} in the \glspl{cpu}, which allows the \glspl{cpu} to run two threads per core, but this is not as efficient as running a single thread per core, as the \glspl{cpu} have to share resources between the two threads.

It is obvious from the multiple graphs and tables that the C\++ implementation is the most energy-efficient and fastest by a significant margin, followed surprisingly by the PyPy execution of the Python code, which is faster than the Go implementation, and the Python implementation is the slowest and most energy-consuming by an extremely large amount.

However, when looking closely at the 28-core and 32-core tests, focusing on C\++, we can see the energy consumption is lower when using cores from different CPUs rather than consuming more, as there is some energy efficiency loss when synchronizing the data between the two CPUs. What happens in this case is that the C\++ parallelization algorithm makes each of the cores have a very hard \gls{cpu} workload, resulting in a more efficient result. This aligns with \autoref{sec:hyperthreading}, where it is explained that hyperthreading is not as efficient for specific tasks.

I want to specifically discuss the 60-core test, as it is the most interesting one. In this test, the energy consumption is lower than in the 48-core test, as well as the execution time on the C\++ implementation, but on the Go implementation, both energy consumption and execution time are higher than in the 48-core test. This is because the Go implementation is not as efficient as the C\++ implementation, and the Go runtime has to manage more goroutines, which adds overhead.

Considering the 32-core and 48-core tests with the Python program, the energy consumption reduces significantly when the program starts using virtual cores, as the program is able to run on more cores, and the Python runtime is not very demanding, being able to use these cores efficiently. As shown in \autoref{fig:server-energy-pkg} and \autoref{fig:server-execution-time}, this is an advantage to Python with respect to itself.


A usually not looked aspect is the energy consumed by the \gls{ram} in the system, which is shown in \autoref{fig:server-energy-ram}. As we can see, the energy consumed by the \gls{ram} is not linear with the number of cores, and after incrementing the cores to more than $8$ cores, the energy consumption does not decrease substantially. But we can see that when using the cores in the same processor, (28 same CPU \& 32 same CPU), the RAM energy consumption is much higher than their counterpart using different processors when using \textbf{C++} or \textbf{Go}. But, at those same core counts, if we check the \textbf{Python} and \textbf{PyPy} implementations, the energy consumption is lower when using the same processor, as the Python runtime is not very demanding and does not require much memory bandwidth, thus being able to use the memory more efficiently.



\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{img/htop_not_running_100_60_cores.png}
    \caption{\gls{htop} showing the cores not being used at 100\% when using many cores for processing in a per-pixel multi threading renderer }
    \label{fig:htop_60_not_100}
\end{figure}

It also must be noted that the cores during the 48 core benchmark were being used at 100\% of their capacity, while in the 60 cores test, the cores were mostly being used at a lower percentage, as shown in \autoref{fig:htop_60_not_100}. This is because the Go runtime is not able to efficiently use all the cores when there are more than 48 cores available, and it is not able to schedule the goroutines efficiently as these routines finish so fast that the Go runtime is not able to keep all the cores busy.

If we changed the implementation to a per-row renderer, on the go-side, the Go runtime would be able to use all the cores more efficiently, as it would be able to schedule the goroutines more efficiently, and the execution time would be lower, but the energy consumption would be higher, as the cores would be used at 100\% of their capacity. Thus, in this case, as we will see in other sections, having a faster execution time is not always the best option in terms of energy consumption.


% When changin to a per-pixel rendered, lower cores energy efficiency increased, but the many cores, from 48 oward would not get used as much, thus reducing the energy efficiency and increating the execution time. 



\subsection{Personal Desktop}
%% Comments on the platform x86, 8 cores, 16 threads, AMR ZEN 2 (https://www.amd.com/en/support/downloads/drivers.html/processors/ryzen/ryzen-3000-series/amd-ryzen-7-3800x.html#amd_support_product_spec)
%% Test with and without hyerthreading as math intensive calculations
\subsubsection{Evaluated parameters}
\subsubsection{Results}

\subsection{Personal SOTA Laptop}
This lapot is said to have one of the fastest single-core performance in the market. It has a 14 core ARM processor, using the big.LITTLE architecture, with 10 high performance cores and 4 high efficiency cores. It has 48GB of RAM, which is enough to run any of the tests.


\subsubsection{Evaluated parameters}

This platform is a personal laptop, with a 14 core processor, the Apple M4 Pro, which has 10 high performance cores and 4 high efficiency cores, which is a big.LITTLE architecture. This means that the high performance cores are used for CPU intensive tasks, while the high efficiency cores are used for less demanding tasks, such as web browsing or watching videos. But as Apple does not allow the user setting the cores to be used by a specific process, like it happens on Linux, we can not test the high efficiency cores isolated from the high performance cores, as the operating system will decide for us which cores to use for each process. 

\subsubsection{Results}

\input{parts/results/mbp-energy}

\input{parts/results/mbp-execution-time.tex}

We can see from \autoref{fig:log-mbp-energy} there does not seem to be a big difference between the execution with one or multiple cores, but this is due to the fact that the table has a logarithmic scale. If we take a look at \autoref{fig:linear-mbp-energy}, we can see that the energy consumption decreases substantially with the Go implementation. But, strangely, both the C\++ and PyPy implementation do not seem to reduce the energy consumption with multiple cores. This seems to be due to the fact that the Apple M4 Pro has a big.LITTLE architecture, and the operating system is not able to efficiently use the high performance cores when there are more than 10 cores available, as it is not able to schedule the tasks efficiently. It could also be that the CPU is drawing its maximum power (around 45-50W) when running the C\++ and PyPy implementations, and thus the energy consumption does not change much with the number of cores as these are quite fast.

This is one of the points that should be studied forward, more testing with ARM chips and a better measurement of the power consumption, with a desktop computer such as the Mac Mini.

Eventhough the energy consumption does not decrease, the execution time does, as we can see from \autoref{fig:mbp-execution-time}. The C\++ implementation is the fastest, followed by the PyPy implementation, then the Go implementation, and finally the Python implementation, which is the slowest by a large margin. I also created this \autoref{tab:mbp-execution-time} to better visualize the execution time of each implementation without Python, as it it distorts the results due to its slow performance.


\subsection{Raspberry Pi 5}
\subsubsection{Evaluated parameters}
\subsubsection{Results}


\section{Comment on parallelizing different languages}

In this section, I would like to make some comment on the parallelization on different languages, and why some might experience a different behavior. 

\subsection{Go}
When choosing how many "cores" the tests are using, for the Go implementation, I used the size of the \texttt{waitChan} channel. This number can be changed to be more than the total number of threads in the system, which sometimes increases the performance.

\input{parts/results/go-routines}

As it can be seen from \autoref{tab:go-routines-cores}, the Go implementation is able to use more than the total number of threads in the system, and it is able to use them efficiently, as the Go runtime is able to schedule the goroutines efficiently.

\subsection{Python}
When iterating though every pixel in Python, as the environment has to be copied for every single pixel, the cores are not being used at 100\% of their capacity, specifically, while testing I saw that the cores were being used at around 5\% of their capacity. Meaning the creation of too many threads is not beneficial, as the overhead of creating the threads is larger than the actual work being done by each thread. 
Another factor that Python, each time a task is submitted to a process, Python needs to serialize (pickle) the entire world object and other parameters, then deserialize them in the worker process, which means that, if this has to happen for every pixel, the serializing and deserializing tasks run for much longer than the actual pixel processing.

\section{Most efficient language optimizations}
As we can see from these results, the most efficient language in terms of energy consumption and execution time is C\++. 

But, out of the box, does C++ always provide the best performance? The answer is no, as the compiler plays an extremely important role in the performance of the code, and the compiler optimizations can make a huge difference in the performance of the code.
For these tests, I many optimization flags, such as \texttt{-O3} and \texttt{-march=native}, which allows the compiler to optimize the code for the specific architecture of the machine it is being compiled on. But what would happen if we used different compiler flags, would the results change? Would another language be more efficient?

As to not leave the reader with the intrigue of what would happen if we used different compiler flags, I have compiled and tested all the programs with the following flags:
\begin{itemize}
    \item \texttt{-O0}: No optimizations, the compiler will not optimize the code at all.
    \item \textbf{-O1}: Basic optimizations; the compiler will optimize the code. It performs a basic cleanup, removing dead code and some simple inlining.
    \item \textbf{-O2}: More optimizations; this is the recommended optimization level for most use cases.
    \item \textbf{-O3}: Maximum optimizations, very aggressive optimizations:
    \begin{itemize}
        \item Loop transformations: Unrolling loops even more than \texttt{-O2}, changing the distribution of loops and interchanging them.
        \item Speculative optimizations
        \item Vectorization: \gls{SIMD} instructions (AVX, SSE, etc.)
        \item Predictive commoning (reusing computations from previous loop iterations)
    \end{itemize}
    \item \textbf{-O3 with --fast-math}: Maximum optimizations; the compiler will optimize the code as much as possible, but operations will not be as precise.
\end{itemize}

As \autocite{llvm-fast-math} explains, the \texttt{--fast-math} flag allows the compiler to perform optimizations that may not be mathematically correct, but will result in faster code. 


\begin{table}
  \centering
  \caption{Power/Energy and execution time for various core counts and compiler optimization flags}
  \label{tab:compiler-optimizations}
  \begin{tabular}{lrrrrr}
    \toprule
    \textbf{Metric / Flags} & \textbf{-O0} & \textbf{-O1} & \textbf{-O2} & \textbf{-O3} & \textbf{-O3 (fast-math)} \\
    \midrule
    \multicolumn{6}{c}{\textbf{1 core}} \\
    power/energy-pkg (J) & 52,957.47 & 5,185.28 & 4,388.12 &  4,031.83   & \textbf{4,005.70} \\
    power/energy-ram (J) & 2,208.08  & 210.28   & 183.21   &    180.00   & \textbf{168.52}  \\
    time (s)             & 270.06    & 27.453   & 24.02    &     23.5993 & \textbf{22.054}  \\
    \midrule
    \multicolumn{6}{c}{\textbf{4 cores}} \\
    power/energy-pkg (J) & 13,379.59 & 1,564.51 & 1,417.01 & \textbf{1,386.60} & 1,414.08       \\
    power/energy-ram (J) & 508.40    & 56.72    & 50.96    &     50.37         & \textbf{49.56}  \\
    time (s)             & 66.066    & 7.4351   & 6.67     &    6.5605         & \textbf{6.478}  \\
    \midrule
    \multicolumn{6}{c}{\textbf{14 cores}} \\
    power/energy-pkg (J) & 5,056.15  & 658.46   & 606.58   & \textbf{595.29}  & 639.00         \\
    power/energy-ram (J) & 153.03    & 20.79    & 18.53    & \textbf{18.24}  & 20.10          \\
    time (s)             & 19.9344   & 2.7184   & 2.42     & \textbf{2.3807} & 2.62           \\
    \midrule
    \multicolumn{6}{c}{\textbf{28 cores}} \\
    power/energy-pkg (J) & 3,650.43  & 627.89   & 565.83   &    561.59   & \textbf{547.56} \\
    power/energy-ram (J) & 120.49    & 20.00    & 18.00    &     17.93   & \textbf{17.47}  \\
    time (s)             & 15.729    & 2.6043   & 2.36     &     2.3382  & \textbf{2.2701} \\
    \midrule
    \multicolumn{6}{c}{\textbf{32 cores}} \\
    power/energy-pkg (J) & 3,353.53  & 606.52   & 552.98   &     548.83  & \textbf{535.22} \\
    power/energy-ram (J) & 110.47    & 19.54    & 17.76    &     17.58   & \textbf{17.27}  \\
    time (s)             & 14.4472   & 2.5369   & 2.33     &     2.3015  & \textbf{2.2368} \\
    \midrule
    \multicolumn{6}{c}{\textbf{60 cores}} \\
    power/energy-pkg (J) & 2,794.03  & 698.96   & 661.76   & \textbf{659.31} & 671.51         \\
    power/energy-ram (J) & 86.80     & 25.37    & 24.11    & \textbf{24.10}  & 24.76          \\
    time (s)             & 7.5463    & 1.89955  & 1.80     &     1.79288     & \textbf{1.79288}\\
    \bottomrule
  \end{tabular}
\end{table}


From the \autoref{tab:compiler-optimizations}, we can see that -O3 can be up to $13.13x$ more efficient and $11.44x$ faster than \texttt{-O0}, and \texttt{-O3} and $13.22x$ more efficient and $12.25x$ faster if we add the \texttt{--fast-math} flag on a single core task. But when we change and add more cores, the improvement decreases up to $4.24x$ faster more energy efficient and $4.16x$ faster with \texttt{-O3} and consume $4.22x$ less energy and take $4.11x$ less time with \texttt{-O3 --fast-math}.

Thus, we can see that the compiler optimizations play a very important role in the performance of the code, and that C\++ is not always the most efficient language, as it depends on the compiler optimizations used. In conclusions, for optimization flags, even though \texttt{-O3 with --fast-math} is the most efficient, I would recommend using \texttt{-O3} for high-performance computing, as it provides a good balance between performance and accuracy. If the program is just a regular program, I would recommend using \texttt{-O2}, as it provides a good balance between performance and code size as well as compilation time, which we have not taken into account as the program is just compiled once and may be executed thousands of times.