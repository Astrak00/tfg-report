\chapter{Evaluation}\label{chap:evaluation}

This section reflects the results of all the testing performed with the different programming languages and architectures / types of computer.

\begin{table}[ht]
  \centering
  \begin{tabular}{lccccc}
    \toprule
               & \gls{OS}       & C++                  & Go       & Python & PyPy \\
    \midrule
    Server     & Ubuntu 24.04.2 &  GCC 14.2.0          & 1.24.2  & 3.12.3 & 7.3.19 \\
    Laptop     & macOS 15.5     &  Apple Clang 17.0.0  & 1.24.2  & 3.13.5 & 7.3.19 \\
    Raspberry  & Debian 12      &  GCC 14.2.0          & 1.24.4  & 3.13.5 & 7.3.19 \\
    Desktop    & Ubuntu 24.04.2 &  GCC 13.3.0          & 1.24.5  & 3.13.5 & 7.3.19 \\
    \bottomrule
  \end{tabular}
  \caption[Language versions and compilers per platform]{Programming languages versions and operating systems used.}
  \label{tab:lang-platforms}
\end{table}

It should be noted that Python should not be used for performance-critical applications, as it is an interpreted language and is not designed for high-performance computing. However, it is an excellent language for rapid prototyping and development, and it is widely used in the industry.

Go's intent is to be a fast, efficient, and easy-to-use language. It is designed for multithreading and concurrency, which makes it a great choice for high-performance computing. Go was specifically designed for backend development for web applications and is widely used in the industry.

The benchmark is run 5 times to obtain a good average. \autoref{chap:appendix-number-benchmarks} shows the percentage change between different runs for different numbers of iterations.

\section{Measurement Platforms}

\subsection{Many-Core Platform}

This platform represents the most powerful as well as power-hungry combination of all devices in my test suite. This is a rack server with two Intel Xeon Gold 6326 processors, each having 16 cores and 32 threads, contributing to a total of 32 cores and 64 threads. It also has the largest amount of \gls{ram} from this testing, with 256GB of \gls{DDR4} memory.

As it has two sockets (one per CPU chip), there must be intercommunication between these processors if a process spreads out to more than 32 threads, or is set by the user using the command \texttt{taskset}, which fixes the cores the process can run on.


\subsubsection{Cache \& Numa}
Regarding the cache of these processors, as it can be seen from \autoref{lst:xeon-cache}, the cache at level 1 has 32 instances of 1.5 MiB of data cache and 1 MiB of instruction cache, half the total number of virtual cores, which is 64. There is also 48MB of L3 cache for each of the two processors.

\begin{lstlisting}[language=bash, caption={Cache of the Intel Xeon Gold 6326}, label={lst:xeon-cache}]
$ lscpu | grep -i cache
Caches (sum of all):
  L1d:                    1.5 MiB (32 instances)
  L1i:                    1 MiB (32 instances)
  L2:                     40 MiB (32 instances)
  L3:                     48 MiB (2 instances)
NUMA:
  NUMA node(s):           2
  NUMA node0 CPU(s):      0-15,32-47
  NUMA node1 CPU(s):      16-31,48-63
\end{lstlisting}

\subsubsection{Core Configurations}

This system was the most versatile in terms of the number of tests that could be performed, as it has many processors and uses Linux on x86, providing a great advantage for forcing processes to run on specific cores.

The tests were conducted on a variety of core configurations, always setting cores in the same processor for core numbers less than 16.

\begin{itemize}
    \item \textbf{1 Core}: Testing with one core, producing the baseline for the program's energy consumption and execution time.
    \item \textbf{2 Cores}: Testing with 2 cores provides the first glimpse of parallelization benefits.
    \item \textbf{4 Cores}: Testing with 4 cores because many computers from some time ago had four cores.
    \item \textbf{8 Cores}: Testing with 8 cores gives us great insight into how many processors in the market work, and it is half the amount of cores inside one chip.
    \item \textbf{14 Cores}: Testing with 14 cores, because it is the number of cores available on the laptop and we wanted to have an execution time comparison.
    \item \textbf{16 Cores}: Testing with 16 cores as it is the amount of real cores on a single chip. This should be one of the most energy-efficient and fastest tests, if there were only one \gls{cpu}.
    \item \textbf{28 Cores (different \glspl{cpu}, all real cores, no logical cores)}: Testing with 28 cores distributed across two sockets is interesting because there has to be information sharing over the bus inside the motherboard to synchronize both \glspl{cpu}. This won't be as energy efficient, but may be faster.
    \item \textbf{28 Cores (same CPU, 16 cores, 32 virtual cores)}: Testing with 28 cores inside the same CPU; the performance should be slower as there are fewer real cores to tackle the work, but it has the advantage of not needing to share data with another socket.
    \item \textbf{32 Cores (same socket)}: Testing with 32 cores in the same socket uses all available logical threads of a system: the 16 real cores and the other 16 threads the \gls{cpu} has thanks to Hyper-Threading.
    \item \textbf{32 Cores (only real cores)}: Testing with 32 real cores across two sockets should be the most powerful combination for CPU-intensive tasks, as all operations should be able to be carried out without many interruptions.
    \item \textbf{48 Cores}: Testing with 48 cores forces us to use all real cores and some logical cores.
    \item \textbf{60 Cores}: Testing with 60 cores is also interesting (not 64), as this would force the machine to interrupt the program we are benchmarking to perform routine operations, such as checking for incoming connections or logging.
\end{itemize}

\subsubsection{Results}

\newlength{\plotwidthgraph}
\newlength{\plotheightgraph}
\setlength{\plotwidthgraph}{14cm}
\setlength{\plotheightgraph}{8cm}

The results for the server are shown in the following figures and tables. The energy consumption is measured in joules, and the execution time is measured in seconds. 

\input{parts/results/server-energy-pkg}

\input{parts/results/server-energy-ram}


\input{parts/results/server-execution-time}
\input{parts/results/server-speedup.tex}


From \autoref{fig:log-server-energy-pkg}, we can see that the energy consumption of the server is not linear with the number of cores. It can be observed that the energy consumption decreases as the number of cores increases, but there is a point in the graph and \autoref{tab:server-energy-pkg} where the energy consumption starts to increase slightly again, as well as the execution times in \autoref{fig:log-server-execution-time}, but not as much as the energy consumption.

This is due to hyperthreading \footnote{Hyperthreading is enabled in this system. To set the process to a fixed \gls{cpu}, I used \texttt{taskset -c [cores]}, i.e., \texttt{taskset -c 0-15,32-47} for running across multiple \glspl{cpu} and \texttt{taskset -c 0-31} to force the program to only run in a single \gls{cpu}.} in the \glspl{cpu}, which allows the \glspl{cpu} to run two threads per core, but this is not as efficient as running a single thread per core, as the \glspl{cpu} have to share resources between the two threads.

It is obvious from the multiple graphs and tables that the C\++ implementation is the most energy-efficient and fastest by a significant margin, followed surprisingly by the PyPy execution of the Python code, which is faster than the Go implementation, and the Python implementation is the slowest and most energy-consuming by an extremely large amount.

However, when looking closely at the 28-core and 32-core tests, focusing on C\++, we can see the energy consumption is lower when using cores from different CPUs rather than consuming more, as there is some energy efficiency loss when synchronizing the data between the two CPUs. What happens in this case is that the C\++ parallelization algorithm makes each of the cores have a very hard \gls{cpu} workload, resulting in a more efficient result. This aligns with \autoref{sec:hyperthreading}, where it is explained that hyperthreading is not as efficient for specific tasks.

I want to specifically discuss the 60-core test, as it is the most interesting one. In this test, the energy consumption is lower than in the 48-core test, as well as the execution time on the C\++ implementation, but on the Go implementation, both energy consumption and execution time are higher than in the 48-core test. This is because the Go implementation is not as efficient as the C\++ implementation, and the Go runtime has to manage more goroutines, which adds overhead.

Considering the 32-core and 48-core tests with the Python program, the energy consumption reduces significantly when the program starts using virtual cores, as the program is able to run on more cores, and the Python runtime is not very demanding, being able to use these cores efficiently. As shown in \autoref{fig:log-server-energy-pkg} and \autoref{fig:log-server-execution-time}, this is an advantage to Python with respect to itself.


A usually not looked aspect is the energy consumed by the \gls{ram} in the system, which is shown in \autoref{fig:log-server-energy-ram}. As we can see, the energy consumed by the \gls{ram} is not linear with the number of cores, and after incrementing the cores to more than $8$ cores, the energy consumption does not decrease substantially. But we can see that when using the cores in the same processor, (28 same CPU \& 32 same CPU), the RAM energy consumption is much higher than their counterpart using different processors when using \textbf{C++} or \textbf{Go}. But, at those same core counts, if we check the \textbf{Python} and \textbf{PyPy} implementations, the energy consumption is lower when using the same processor, as the Python runtime is not very demanding and does not require much memory bandwidth, thus being able to use the memory more efficiently.



\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{img/htop_not_running_100_60_cores.png}
    \caption[Core usage per pixel renderer]{\gls{htop} showing the cores not being used at 100\% when using many cores for processing in a per-pixel multi threading renderer }
    \label{fig:htop_60_not_100}
\end{figure}

It also must be noted that the cores during the 48 core benchmark were being used at 100\% of their capacity, while in the 60 cores test, the cores were mostly being used at a lower percentage, as shown in \autoref{fig:htop_60_not_100}. This is because the Go runtime is not able to efficiently use all the cores when there are more than 48 cores available, and it is not able to schedule the goroutines efficiently as these routines finish so fast that the Go runtime is not able to keep all the cores busy.

If we changed the implementation to a per-row renderer, on the go-side, the Go runtime would be able to use all the cores more efficiently, as it would be able to schedule the goroutines more efficiently, and the execution time would be lower, but the energy consumption would be higher, as the cores would be used at 100\% of their capacity. Thus, in this case, as we will see in other sections, having a faster execution time is not always the best option in terms of energy consumption.


All the raw data for the benchmarks can be found in the \autoref{chap:appendix-server-benchmarks}.

% When changin to a per-pixel rendered, lower cores energy efficiency increased, but the many cores, from 48 oward would not get used as much, thus reducing the energy efficiency and increating the execution time. 



\subsection{Desktop}
This platform is one of the most common in the amateur market, as it is a personal desktop computer with a Ryzen 3800x processor, which has 8 cores and 16 threads and has 32GB of RAM. It has a Zen 2 architecture, which has heterogeneous cores. These tests were performed with hyperthreading enabled, as it is the most popular configuration, and the default configuration. 

\subsubsection{Cache \& Numa}
The cache of the AMD Ryzen 3800x is shown in \autoref{lst:ryzen-cache}. As we can see, it has 8 instances of 256 KiB of L1 data cache and 256 KiB of L1 instruction cache, which is half the number of threads available in the system (the same as the server platform). It has also two L3 caches of 32 MiB each, which is due to the processor having two \glspl{CCX}. 

\begin{lstlisting}[language=bash, caption={Cache of the AMD Ryzen 3800x}, label={lst:ryzen-cache}]
$ lscpu | grep -i cache
Caches (sum of all):
  L1d:                    256 KiB (8 instances)
  L1i:                    256 KiB (8 instances)
  L2:                     4 MiB (8 instances)
  L3:                     32 MiB (2 instances)
NUMA:
  NUMA node(s):           1
  NUMA node0 CPU(s):      0-7
\end{lstlisting}


\subsubsection{Results}

\input{parts/results/desktop-energy}

\input{parts/results/desktop-execution}
\input{parts/results/desktop-speedup.tex}

These results show a clear trend in the energy consumption and execution time of the different programming languages. The C\++ implementation is the most energy-efficient, as expected, but again, PyPy surprises with its results, being the second most energy-efficient and being much closer to the \gls{CPP} implementation than the Go implementation, which is the third most energy-efficient. Specific numbers for energy consumption and execution time can be found in \autoref{tab:desktop-energy-pkg-hyperthreading} and \autoref{tab:desktop-execution-time-hyperthreading}.

We can also see from the graphs \autoref{fig:linear-desktop-energy-hyperthreading} and \autoref{fig:linear-desktop-execution-time-hyperthreading} that the difference between the 8 core test and the 16 core test is not as big as in the server as the processor only has 8 real cores, and the other 8 are hyperthreaded cores, thus they are not as powerful as the other 8. 

This can also be seen very clearly in the energy consumption of the PyPy and Python tests in \autoref{fig:linear-desktop-energy-hyperthreading} (\autoref{tab:desktop-energy-pkg-hyperthreading}) that when using more than 8 cores makes the energy consumption as the number of threads use separates from 8 (the number of real cores). This also affects the execution time but not as significantly, as we can see in \autoref{fig:linear-desktop-execution-time-hyperthreading} (\autoref{tab:desktop-execution-time-hyperthreading}), where the execution time does not change much when using more than 8 cores, but the energy consumption does.

All the raw data for the benchmarks can be found in the \autoref{chap:appendix-desktop-benchmarks}.

\subsection{Laptop}
This laptop is said to have one of the fastest single-core performance in the market. It has a 14 core ARM processor, using the big.LITTLE architecture, with 10 high performance cores and 4 high efficiency cores. It has 48GB of RAM, which is enough to run any of the tests.


This platform is a personal laptop, with a 14 core processor, the Apple M4 Pro, which has 10 high performance cores and 4 high efficiency cores, which is a big.LITTLE architecture. This means that the high performance cores are used for CPU intensive tasks, while the high efficiency cores are used for less demanding tasks, such as web browsing or watching videos. But as Apple does not allow the user setting the cores to be used by a specific process, like it happens on Linux, we can not test the high efficiency cores isolated from the high performance cores, as the operating system will decide for us which cores to use for each process. 

\subsubsection{Cache \& Numa}

\begin{lstlisting}[language=bash, caption={Cache of the Apple M4 Pro by performance level}, label={lst:apple-cache}]
Performance Level 0 (High-Performance Cores (10x)):
  Level   Type   Size
  L1d     Data   128 KB
  L1i     Inst   192 KB
  L2      Uni    16 MB

Performance Level 1 (Efficiency Cores (4x)):
  Level   Type   Size
  L1d     Data   64 KB
  L1i     Inst   128 KB
  L2      Uni    4 MB
\end{lstlisting}

\subsubsection{Results}

\input{parts/results/mbp-energy}

\input{parts/results/mbp-execution-time.tex}
\input{parts/results/laptop-speedup.tex}

We can see from \autoref{fig:log-mbp-energy} there does not seem to be a big difference between the execution with one or multiple cores, but this is due to the fact that the table has a logarithmic scale. If we take a look at \autoref{fig:linear-mbp-energy}, we can see that the energy consumption decreases substantially with the Go implementation. But, strangely, both the C\++ and PyPy implementation do not seem to reduce the energy consumption with multiple cores. This seems to be due to the fact that the Apple M4 Pro has a big.LITTLE architecture, and the operating system is not able to efficiently use the high performance cores when there are more than $10$ cores available, as it is not able to schedule the tasks efficiently. It could also be that the CPU is drawing its maximum power (around $45-50W$) when running the C\++ and PyPy implementations, and thus the energy consumption does not change much with the number of cores as these are quite fast. \footnote{This is one of the points that should be studied forward, more testing with ARM chips and a better measurement of the power consumption, with a desktop computer such as the Mac Mini.}



Even though the energy consumption does not decrease, the execution time does, as we can see from \autoref{fig:log-mbp-execution-time}. The C++ implementation is the fastest, followed by the PyPy implementation, then the Go implementation, and finally the Python implementation, which is the slowest by a large margin. I also created this \autoref{fig:linear-mbp-execution-time} to better visualize the execution time of each implementation without Python, as it distorts the results due to its slow performance. Raw data for both energy consumption and execution time can be found in \autoref{tab:mbp-power-consumption} and \autoref{tab:mbp-time-execution} respectively.

All the raw data for the benchmarks can be found in the \autoref{chap:appendix-laptop-benchmark}.

\subsection{Raspberry Pi 5}
This SBC (Single Board Computer) is one of the most popular in the market, and though is is nota great platform for testing the performance of different programming languages its popularity has made it an interesting option as it has much less power requirements than the other alternatives. It has a 4 core ARM processor, 8GB of RAM, which is enough to run any of the tests. 

\subsubsection{Results}

\input{parts/results/rpi-energy}

\input{parts/results/rpi-execution}
\input{parts/results/raspberry-speedup.tex}

From both \autoref{fig:log-rpi-energy} and \autoref{fig:log-rpi-execution} we can see that the trend lines, in this case intersect, meaning that passing from 2 to 4 cores, the energy increases for the PyPy implementation and decreases for the rest of the implementation. This is due to the fact that the Raspberry Pi 5 has a much less powerfull processor and thus, compiled languages such as C++ and Go can obtain better power efficiency results when using more cores, as the processor is able to handle the load better. 

It is impressive the slowness that python shows in this platform, $62$x less power efficient than PyPy and consuming more than $147$x the energy of the C++ implementation. 

If we turn to the execution times, we can see that the C++ implementation is the fastest, followed by the Go implementation, then PyPy and lastly Python when looking at the 4 cores run of the benchmark. But, when the program was run with 2 cores, the PyPy implementation does not reduce much the execution time, compared to the Go result, interchanging the position of the Go and PyPy implementations, as it can be seen in clearer in the raw data in \autoref{tab:execution-time-by-cores} and \autoref{tab:power-sum-by-cores}.

All the raw data for the benchmarks can be found in the \autoref{chap:appendix-rpi-benchmark}.

\section{Comment on parallelizing different languages}

In this section, I would like to make some comment on the parallelization on different languages, and why some might experience a different behavior. 

\subsection{Go}
When choosing how many `cores' the tests are using, for the Go implementation, I used the size of the \texttt{waitChan} channel. This number can be changed to be more than the total number of threads in the system, which sometimes increases the performance.

\input{parts/results/go-routines}

As it can be seen from \autoref{tab:go-routines-cores}, the Go implementation is able to use more than the total number of threads in the system, and it is able to use them efficiently, as the Go runtime is able to schedule the goroutines efficiently. We can also observe from the table, that the results that are run in the same CPU chip versus different CPU chips, have similar energy consumptions, but the execution times are significantly lower as there are no context switches happening between the two CPUs. This can be seen in the 28 cores same CPU and 32 cores same CPU tests, marked in \autoref{tab:go-routines-cores} with a \textbf{*}.

\subsection{Python}
When iterating though every pixel in Python, as the environment has to be copied for every single pixel, the cores are not being used at 100\% of their capacity, specifically, while testing I saw that the cores were being used at around 5\%-15\% of their capacity. Meaning the creation of too many threads is not beneficial, as the overhead of creating the threads is larger than the actual work being done by each thread. 
Another factor that Python, each time a task is submitted to a process, Python needs to serialize (pickle) the entire world object and other parameters, then deserialize them in the worker process, which means that, if this has to happen for every pixel, the serializing and deserializing tasks run for much longer than the actual pixel processing.

\section{Most efficient language optimizations}
As we can see from these results, the most efficient language in terms of energy consumption and execution time is C\++. 

But, out of the box, does C++ always provide the best performance? The answer is no, as the compiler plays an extremely important role in the performance of the code, and the compiler optimizations can make a huge difference in the performance of the code.
For these tests, I many optimization flags, such as \texttt{-O3} and \texttt{-march=native}, which allows the compiler to optimize the code for the specific architecture of the machine it is being compiled on. But what would happen if we used different compiler flags, would the results change? Would another language be more efficient?

As to not leave the reader with the intrigue of what would happen if we used different compiler flags, I have compiled and tested all the programs with the following flags:
\begin{itemize}
    \item \texttt{-O0}: No optimizations, the compiler will not optimize the code at all.
    \item \textbf{-O1}: Basic optimizations; the compiler will optimize the code. It performs a basic cleanup, removing dead code and some simple inlining.
    \item \textbf{-O2}: More optimizations; this is the recommended optimization level for most use cases.
    \item \textbf{-O3}: Maximum optimizations, very aggressive optimizations:
    \begin{itemize}
        \item Loop transformations: Unrolling loops even more than \texttt{-O2}, changing the distribution of loops and interchanging them.
        \item Speculative optimizations
        \item Vectorization: \gls{SIMD} instructions (AVX, SSE, etc.)
        \item Predictive commoning (reusing computations from previous loop iterations)
    \end{itemize}
    \item \textbf{-O3 with --fast-math}: Maximum optimizations; the compiler will optimize the code as much as possible, but operations will not be as precise.
\end{itemize}

As \autocite{llvm-fast-math} explains, the \texttt{--fast-math} flag allows the compiler to perform optimizations that may not be mathematically correct, but will result in faster code. 


\input{parts/results/compiler-optimizations}


From the \autoref{tab:compiler-optimizations}, we can see that -O3 can be up to $13.13x$ more efficient and $11.44x$ faster than \texttt{-O0}, and \texttt{-O3} and $13.22x$ more efficient and $12.25x$ faster if we add the \texttt{--fast-math} flag on a single core task. But when we change and add more cores, the improvement decreases up to $4.24x$ faster more energy efficient and $4.16x$ faster with \texttt{-O3} and consume $4.22x$ less energy and take $4.11x$ less time with \texttt{-O3 --fast-math}.

Thus, we can see that the compiler optimizations play a very important role in the performance of the code, and that C\++ is not always the most efficient language, as it depends on the compiler optimizations used. In conclusions, for optimization flags, even though \texttt{-O3 with --fast-math} is the most efficient, I would recommend using \texttt{-O3} for high-performance computing, as it provides a good balance between performance and accuracy. If the program is just a regular program, I would recommend using \texttt{-O2}, as it provides a good balance between performance and code size as well as compilation time, which we have not taken into account as the program is just compiled once and may be executed thousands of times.